{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93e38185",
   "metadata": {},
   "source": [
    "# Extension Exercises\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a1c8e22",
   "metadata": {},
   "source": [
    "<div align=\"right\"><button><a href=\"https://colab.research.google.com/github/QuantEcon/workshop.africa-july2023/blob/main/day-10/exercise_set_10_with_solution.ipynb\"><img src=\"\" heght=\"10px\"/><img\n",
    "  src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
    "  alt=\"open with Colab\" width=\"100px\"/></a></button></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cd356b2",
   "metadata": {},
   "source": [
    "#### Written for the QuantEcon Africa Workshop (July 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0cdb9de",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "***Exercise 1.1*** Consider the following setup:\n",
    "\n",
    "Given we have no prior knowledge about whether a coin is fair or unfair (that is we do not know whether the coin has a probability of head (p) equals to 0.5 or other values). In light of this prior belief, we assign a uniform prior to the probability of heads, $\\theta$. \n",
    "\n",
    "Your task is to write a function that takes a sequence of observations of coin flips, update belief after each flip, and returns the posterior distribution of $\\theta$ on a grid of points between 0 and 1. Set the true value of $\\theta$ to 0.7 and the number of coin flips ($n$) to 10000.\n",
    "\n",
    "(Hint: think about what distribution does coin flip follow?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e96a1385",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50_000 # Number of coin flips\n",
    "bias = 0.7 # The true bias\n",
    "\n",
    "xs = np.linspace(0, 1, 101) # The grid\n",
    "Œ∏ = np.repeat(1/len(xs), len(xs)) # Uniform Œ∏\n",
    "\n",
    "def coin_flips(n, bias):\n",
    "    # Simulate n coin flips with bias\n",
    "    return np.random.choice([0, 1], size=n, p=[1-bias, bias])\n",
    "\n",
    "flips = coin_flips(n, bias)\n",
    "\n",
    "posterior_list = []\n",
    "for flip in flips:\n",
    "    likelihood = xs**flip * (1-xs)**(1-flip) # Bernoulli Likelihood\n",
    "    updated_beliefs = likelihood * Œ∏\n",
    "    posterior = likelihood * Œ∏ / np.sum(updated_beliefs)\n",
    "    posterior_list.append(Œ∏)\n",
    "    Œ∏ = posterior\n",
    "posterior = posterior_list[-1]\n",
    "\n",
    "plt.plot(xs, posterior, color='black', alpha=0.4)\n",
    "plt.vlines(bias, 0, np.max(posterior), color='black', linestyles='--')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9437c586",
   "metadata": {},
   "source": [
    "***Exercise 1.2*** Now instead of assuming a uniform prior on $[0, 1]$, assume the grid is restricted  to $[0.6, 0.8]$. What is the posterior distribution of $\\theta$ after 100, 200, ..., 10000 coin flips? Visualize the distribution if you can."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ac5faa5",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000 # Number of coin flips\n",
    "bias = 0.7 # The true bias\n",
    "\n",
    "def simulate(n, bias):\n",
    "    xs = np.linspace(0.6, 0.8, 101) # The grid\n",
    "    Œ∏ = np.repeat(1/len(xs), len(xs)) # Uniform Œ∏\n",
    "\n",
    "    def coin_flips(n, bias):\n",
    "        # Simulate n coin flips with bias\n",
    "        return np.random.choice([0, 1], size=n, p=[1-bias, bias])\n",
    "\n",
    "    flips = coin_flips(n, bias)\n",
    "\n",
    "    posterior_list = []\n",
    "    for flip in flips:\n",
    "        likelihood = xs**flip * (1-xs)**(1-flip) # Bernoulli Likelihood\n",
    "        updated_beliefs = likelihood * Œ∏\n",
    "        Œ∏ = likelihood * Œ∏ / np.sum(updated_beliefs)\n",
    "        posterior_list.append(Œ∏)\n",
    "\n",
    "    posterior = posterior_list[-1]\n",
    "    plt.plot(xs, posterior, color='grey', alpha=0.2)\n",
    "\n",
    "for i in range(100, n+1, 100):\n",
    "    if i % 2000 == 0:\n",
    "        print(f\"Simulating {i} coin flips...\")\n",
    "    simulate(i, bias)\n",
    "\n",
    "plt.axvline(bias, color='black')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7165202d",
   "metadata": {},
   "source": [
    "***Exercise 1.3*** [Beta-binomial model](https://en.wikipedia.org/wiki/Beta-binomial_distribution#Beta-binomial_in_Bayesian_statistics) is well studied due to their conjugacy. Please show that the update in Exercise 1.1 fit into the construct of beta-binomial model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9d2b85c",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c09a2af",
   "metadata": {},
   "source": [
    "$\\theta |_{\\alpha = \\beta = 1} \\sim Unif(0, 1)$ in Exercise 1.1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c12f343f",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "In this exercise, please show the fact we noticed in Exercise 1.3 mathematically."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15b864de",
   "metadata": {},
   "source": [
    "***Exercise 2.1*** Please write down the likelihood function for $\\theta$ after observing one flip of our coin."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bef39363",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a8f7b15",
   "metadata": {},
   "source": [
    "Suppose the outcome is Y, then the likelihood function is\n",
    "\n",
    "$$\n",
    "L(Y|\\theta)= \\textrm{Prob}(X =  Y | \\theta) = \n",
    "\\theta^Y (1-\\theta)^{1-Y}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ead46e3",
   "metadata": {},
   "source": [
    "***Exercise 2.2*** Please write the prior distribution (in terms of $\\alpha$ and $\\beta$) for $\\theta$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2faecc1d",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46d9e8a2",
   "metadata": {},
   "source": [
    "The prior distribution is\n",
    "\n",
    "$$\n",
    "\\textrm{Prob}(\\theta) = \\frac{\\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}}{B(\\alpha, \\beta)}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de94a34c",
   "metadata": {},
   "source": [
    "***Exercise 2.3*** Please write the posterior distribution for $\\theta$ after observing one flip of our coin."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "502c2f85",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2572bc12",
   "metadata": {},
   "source": [
    "We can derive the posterior distribution for $\\theta$ via \n",
    "\n",
    "\\begin{align*}\n",
    "  \\textrm{Prob}(\\theta | Y) &= \\frac{\\textrm{Prob}(Y | \\theta) \\textrm{Prob}(\\theta)}{\\textrm{Prob}(Y)} \\\\\n",
    "  &=\\frac{\\textrm{Prob}(Y | \\theta) \\textrm{Prob}(\\theta)}{\\int_{0}^{1} \\textrm{Prob}(Y | \\theta) \\textrm{Prob}(\\theta) d \\theta }\\\\\n",
    "  &= \\frac{\\theta^Y (1-\\theta)^{1-Y}\\frac{\\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}}{B(\\alpha, \\beta)}}{\\int_{0}^{1}\\theta^Y (1-\\theta)^{1-Y}\\frac{\\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}}{B(\\alpha, \\beta)} d \\theta } \\\\\n",
    "  &= \\frac{ \\theta^{Y+\\alpha - 1} (1 - \\theta)^{1-Y+\\beta - 1}}{\\int_{0}^{1}\\theta^{Y+\\alpha - 1} (1 - \\theta)^{1-Y+\\beta - 1} d \\theta}\n",
    "\\end{align*}\n",
    "\n",
    "which means that\n",
    "\n",
    "$$\n",
    "\\textrm{Prob}(\\theta | Y) \\sim \\textrm{Beta}(\\alpha + Y, \\beta + (1-Y))\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac5b35c3",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "[Inverse transform sampling](https://python.quantecon.org/prob_matrix.html#classic-trick-for-generating-random-numbers) is a classic method used to generate random numbers from a desired probability distribution. The basic idea behind inverse transform sampling is to transform uniform random numbers into random numbers that follow the desired distribution.\n",
    "\n",
    "\n",
    "The core idea is that if we draw a random number $u$ from a uniform distribution on $[0, 1]$, then the random variable $F^{-1}(u)$ has the distribution $F$:\n",
    "\n",
    "$$\n",
    "X=F^{-1}(U)\n",
    "$$\n",
    "\n",
    "where X is a random variable with CDF $F$:\n",
    "\n",
    "$$\n",
    "F_X(x)=F(x)=\\textrm{Prob}\\{X\\le x\\}\n",
    "$$\n",
    "\n",
    "A general algorithm for inverse transform sampling is as follows:\n",
    "\n",
    "1. Draw a random number $u$ from a uniform distribution on $[0, 1]$.\n",
    "\n",
    "2. Compute $x=F^{-1}(u)$.\n",
    "\n",
    "3. $x$ is a random number from the distribution $F$.\n",
    "\n",
    "Implement the inverse transform sampling algorithm for the exponential distribution with parameter $\\lambda$ = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5683f4b3",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "Œª = 0.5\n",
    "\n",
    "# Number of random samples to generate\n",
    "num_samples = 1000\n",
    "\n",
    "# Inverse transform sampling\n",
    "def inverse_transform_sampling(num_samples, Œª):\n",
    "    u = np.random.uniform(0, 1, num_samples)  # Generate uniform random numbers\n",
    "    x = -np.log(1 - u) / Œª  # Apply inverse transform to get exponential random numbers\n",
    "    return x\n",
    "\n",
    "# Generate random samples\n",
    "samples = inverse_transform_sampling(num_samples, Œª)\n",
    "\n",
    "# Plot the histogram of the generated samples\n",
    "plt.hist(samples, bins=30, density=True, alpha=0.5, label='Generated samples')\n",
    "\n",
    "x = np.linspace(0, 10, 1000)\n",
    "plt.plot(x, expon.pdf(x, scale=1/Œª),\n",
    "       'r-', lw=2, alpha=0.5, label='expon pdf')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability density')\n",
    "plt.title('Inverse Transform Sampling')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f86e1f1d",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Consider the stochastic second-order linear difference equation\n",
    "\n",
    "$$\n",
    "y_{t} = \\alpha_{0} + \\alpha_{1} y_{y-1} + \\alpha_{2} y_{t-2} + u_{t}\n",
    "$$\n",
    "\n",
    "where $u_{t} \\sim N \\left(0, \\sigma_{u}^{2}\\right)$ and\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{c}\n",
    "y_{-1}\\\\\n",
    "y_{0}\n",
    "\\end{array}\\right]\\sim N\\left(\\mu_{\\tilde{y}},\\Sigma_{\\tilde{y}}\\right)\n",
    "$$\n",
    "\n",
    "It can be written as a stacked system\n",
    "\n",
    "$$\n",
    "\\underset{\\equiv A}{\\underbrace{\\left[\\begin{array}{cccccccc}\n",
    "1 & 0 & 0 & 0 & \\cdots & 0 & 0 & 0\\\\\n",
    "-\\alpha_{1} & 1 & 0 & 0 & \\cdots & 0 & 0 & 0\\\\\n",
    "-\\alpha_{2} & -\\alpha_{1} & 1 & 0 & \\cdots & 0 & 0 & 0\\\\\n",
    "0 & -\\alpha_{2} & -\\alpha_{1} & 1 & \\cdots & 0 & 0 & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\cdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & 0 & \\cdots & -\\alpha_{2} & -\\alpha_{1} & 1\n",
    "\\end{array}\\right]}}\\left[\\begin{array}{c}\n",
    "y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "y_{3}\\\\\n",
    "y_{4}\\\\\n",
    "\\vdots\\\\\n",
    "y_{T}\n",
    "\\end{array}\\right]=\\underset{\\equiv b}{\\underbrace{\\left[\\begin{array}{c}\n",
    "\\alpha_{0}+\\alpha_{1}y_{0}+\\alpha_{2}y_{-1}\\\\\n",
    "\\alpha_{0}+\\alpha_{2}y_{0}\\\\\n",
    "\\alpha_{0}\\\\\n",
    "\\alpha_{0}\\\\\n",
    "\\vdots\\\\\n",
    "\\alpha_{0}\n",
    "\\end{array}\\right]}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3dff9f4e",
   "metadata": {},
   "source": [
    "***Exercise 4.1*** Code the stacked system using the parameters below as $A$ and calculate the inverse of the system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b41c5b24",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "T = 160\n",
    "\n",
    "# coefficients of the second order difference equation\n",
    "ùõº0 = 10\n",
    "ùõº1 = 1.53\n",
    "ùõº2 = -.9\n",
    "\n",
    "# variance of u (\\sigma_u^2)\n",
    "œÉu = 10.\n",
    "\n",
    "# distribution of y_{-1} and y_{0}\n",
    "Œºy_tilde = np.array([1., 0.5])\n",
    "Œ£y_tilde = np.array([[2., 1.], [1., 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct A and A^{\\prime}\n",
    "A = np.zeros((T, T))\n",
    "\n",
    "for i in range(T):\n",
    "    A[i, i] = 1\n",
    "\n",
    "    if i-1 >= 0:\n",
    "        A[i, i-1] = -ùõº1\n",
    "\n",
    "    if i-2 >= 0:\n",
    "        A[i, i-2] = -ùõº2\n",
    "\n",
    "A_inv = np.linalg.inv(A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87e84f22",
   "metadata": {},
   "source": [
    "***Exercise 4.2*** We can compute $y$ by solving the system\n",
    "\n",
    "$$\n",
    "y = A^{-1} \\left(b + u\\right)\n",
    "$$\n",
    "\n",
    "Please solve for $\\mu_{y}$ and $\\Sigma_{y}$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7915a67f",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66366cbb",
   "metadata": {},
   "source": [
    "We have\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu_{y} &= A^{-1} \\mu_{b} \\\\\n",
    "\\Sigma_{y} &= A^{-1} E \\left[\\left(b - \\mu_{b} + u \\right) \\left(b - \\mu_{b} + u \\right)^{\\prime}\\right] \\left(A^{-1}\\right)^{\\prime} \\\\\n",
    "           &= A^{-1} \\left(\\Sigma_{b} + \\Sigma_{u} \\right) \\left(A^{-1}\\right)^{\\prime}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\mu_{b}=\\left[\\begin{array}{c}\n",
    "\\alpha_{0}+\\alpha_{1}\\mu_{y_{0}}+\\alpha_{2}\\mu_{y_{-1}}\\\\\n",
    "\\alpha_{0}+\\alpha_{2}\\mu_{y_{0}}\\\\\n",
    "\\alpha_{0}\\\\\n",
    "\\vdots\\\\\n",
    "\\alpha_{0}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma_{b}=\\left[\\begin{array}{cc}\n",
    "C\\Sigma_{\\tilde{y}}C^{\\prime} & \\boldsymbol{0}_{N-2\\times N-2}\\\\\n",
    "\\boldsymbol{0}_{N-2\\times2} & \\boldsymbol{0}_{N-2\\times N-2}\n",
    "\\end{array}\\right],\\quad C=\\left[\\begin{array}{cc}\n",
    "\\alpha_{2} & \\alpha_{1}\\\\\n",
    "0 & \\alpha_{2}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma_{u}=\\left[\\begin{array}{cccc}\n",
    "\\sigma_{u}^{2} & 0 & \\cdots & 0\\\\\n",
    "0 & \\sigma_{u}^{2} & \\cdots & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & \\sigma_{u}^{2}\n",
    "\\end{array}\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean vectors of b and y\n",
    "Œºb = np.full(T, ùõº0)\n",
    "Œºb[0] += ùõº1 * Œºy_tilde[1] + ùõº2 * Œºy_tilde[0]\n",
    "Œºb[1] += ùõº2 * Œºy_tilde[1]\n",
    "\n",
    "Œºy = A_inv @ Œºb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a153c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the covariance matrices of b and y\n",
    "Œ£u = np.eye(T) * œÉu ** 2\n",
    "\n",
    "Œ£b = np.zeros((T, T))\n",
    "\n",
    "C = np.array([[ùõº2, ùõº1], [0, ùõº2]])\n",
    "Œ£b[:2, :2] = C @ Œ£y_tilde @ C.T\n",
    "\n",
    "Œ£y = A_inv @ (Œ£b + Œ£u) @ A_inv.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bdd3490",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "Congratulations for making it to the end of the workshop! We hope you have enjoyed the workshop and learned a lot.\n",
    "\n",
    "Please run through [more advanced QuantEcon lecture series](https://quantecon.org/projects/#filter=lecture) and see what you can do with the tools you have learned in this workshop.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
