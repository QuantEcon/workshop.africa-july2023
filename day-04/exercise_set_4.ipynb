{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pnHB5q0yBp7"
   },
   "source": [
    "# Scientific Libraries, Monte Carlo, and More Linear Algebra Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\"><button><a href=\"https://colab.research.google.com/github/QuantEcon/workshop.africa-july2023/blob/main/day-04/exercise_set_4.ipynb\"><img src=\"\" heght=\"10px\"/><img\n",
    "    src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
    "    alt=\"open with Colab\" width=\"100px\"/></a></button></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Written for the QuantEcon Africa Workshop (July 2023)\n",
    "#### Author: [Smit Lunagariya](https://github.com/Smit-create), [Humphrey Yang](https://github.com/HumphreyYang) and [Shu Hu](https://shu-hu.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the exercises on scientific libraries, Monte Carlo simulation, eigenvalues and eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "B4DjbqlLyYXB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import eig\n",
    "from numpy.random import randn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Before you attempt these exercises, we recommend that you read\n",
    "\n",
    "1. the [lecture on NumPy](https://python-programming.quantecon.org/numpy.html),\n",
    "2. the [lecture on Matplotlib](https://python-programming.quantecon.org/matplotlib.html) and\n",
    "3. the [lecture on SciPy](https://python-programming.quantecon.org/scipy.html).\n",
    "4. the [lecture on Eigenvalues and Eigenvectrors](https://intro.quantecon.org/eigen_I.html).\n",
    "5. the [An introduction to Monte Carlo](https://intro.quantecon.org/monte_carlo.html#an-introduction-to-monte-carlo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Given a matrix $A$, compute the eigenvalues and eigenvectors and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4],\n",
       "       [5, 7]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 4], [5, 7]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "In this exercise, \n",
    "\n",
    "1. Draw 1000 independent draws from the standard normal distribution using [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html).\n",
    "\n",
    "2. Calculate the sample mean and variance of the draws and compare them to the theoretical values.\n",
    "\n",
    "3. Visualize the empirical distribution of the draws using a histogram. Mark the sample mean and $\\pm$ one standard deviation using vertical lines.\n",
    "\n",
    "4. Calculate the probability that a draw from the distribution is less than 0 and compare it to the proportion of the sample that is less than 0.\n",
    "\n",
    "5. How do the results in question 3 change with different sample sizes? Try to draw 10, 100, 500, 1000, and 10000 samples, each with 100 times and plot the results.\n",
    "\n",
    "Use the following imports to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Put your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Consider a random variable $S$ in the following form\n",
    "\n",
    "$$\n",
    "S = \\left ( \\sum^M_{i=1} X_i \\right )^p\n",
    "$$\n",
    "\n",
    "where $X_i \\sim LN (\\mu_i, \\sigma_i)$, $M\\in \\mathbb N$ and $p$ is a positive number known to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1\n",
    "\n",
    "First let $M=1$ and $p=1$. Now we have\n",
    "\n",
    "$$\n",
    "    S = X_1\n",
    "$$\n",
    "where $X_1 \\sim LN (\\mu_1, \\sigma_1)$.\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "**Exercise 3.1.1**\n",
    "\n",
    "Write down the analytical solutions to $\\mathbb E S$ and $\\mathop{\\mathrm{Var}} S$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your answers in the markdown cell above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.1.2**\n",
    "\n",
    "Define two Python functions `mean_analytical` and `var_analytical` to compute the $\\mathbb E S$ and $\\mathop{\\mathrm{Var}} S$ directly according to their analytical solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_analytical(μ_1, σ_1):\n",
    "    # TODO: Write your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_analytical(μ_1, σ_1):\n",
    "    # TODO: Write your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.1.3**\n",
    "\n",
    "Given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1_000_000\n",
    "p = 1\n",
    "μ_1 = 0.2\n",
    "σ_1 = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate $\\mathbb E S$ by Monte Carlo simulation using loop. \n",
    "\n",
    "Compare the result with the analytical solution.\n",
    "\n",
    "Hint. \n",
    "$$\n",
    "\\mathbb E S \\approx  \n",
    "\\frac{1}{n} \\sum_{i=1}^n S_i    \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.1.4**\n",
    "\n",
    "With the same setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1_000_000\n",
    "p = 1\n",
    "μ_1 = 0.2\n",
    "σ_1 = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and given $\\mathbb ES$, approximate $\\mathop{\\mathrm{Var}} S$ by Monte Carlo simulation.\n",
    "\n",
    "Compare it with the analytical solution.\n",
    "\n",
    "Hint. Note that $\\mathop{\\mathrm{Var}} S = \\mathbb E \\left [S - \\mathbb E S \\right ]^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.1.5**\n",
    "\n",
    "With the same setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1_000_000\n",
    "p = 1\n",
    "μ_1 = 0.2\n",
    "σ_1 = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite the loops in Exercises 1.1.3 and 1.1.4 with vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.2\n",
    "\n",
    "Let $M=3$. Then we have\n",
    "\n",
    "$$\n",
    "    S = (X_1 + X_2 + X_3)^p\n",
    "$$\n",
    "which is the same form as our lecture [here](https://intro.quantecon.org/monte_carlo.html#share-price-with-unknown-distribution).\n",
    "\n",
    "Now we don't have analytical solutions for $\\mathbb E S$ and $\\mathop{\\mathrm{Var}} S$.\n",
    "\n",
    "We use the following values for $ p $ and each $ \\mu_i $ and $ \\sigma_i $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1_000_000\n",
    "p = 0.5\n",
    "μ_1, μ_2, μ_3 = 0.2, 0.8, 0.4\n",
    "σ_1, σ_2, σ_3 = 0.1, 0.05, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_vectorized(n=1_000_000):\n",
    "    X_1 = np.exp(μ_1 + σ_1 * randn(n))\n",
    "    X_2 = np.exp(μ_2 + σ_2 * randn(n))\n",
    "    X_3 = np.exp(μ_3 + σ_3 * randn(n))\n",
    "    S = (X_1 + X_2 + X_3)**p\n",
    "    return S.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo simulation of ES in vectorization is  2.2297060186121893\n"
     ]
    }
   ],
   "source": [
    "S_mean_mc_new = compute_mean_vectorized(n)\n",
    "print(\"Monte Carlo simulation of ES in vectorization is \", S_mean_mc_new)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.2.1** \n",
    "\n",
    "Given the monte carlo simulation of $\\mathbb ES$, approximate $\\mathop{\\mathrm{Var}} S$ by Monte Carlo simulation using loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.2.2**\n",
    "\n",
    "Rewrite the loop in Exercise 3.2.1 with vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate and plot the correlated time series\n",
    "\n",
    "$$\n",
    "    x_{t+1} = \\alpha \\, x_t + \\epsilon_{t+1}\n",
    "    \\quad \\text{where} \\quad\n",
    "    x_0 = 0 \n",
    "    \\quad \\text{and} \\quad t = 0,\\ldots,T\n",
    "$$\n",
    "\n",
    "Here $\\{\\epsilon_t\\}$ is iid and standard normal.\n",
    "\n",
    "In your solution, restrict your import statements to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import normalvariate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set $T=200$ and $\\alpha = 0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Put your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On day 2, we generated 100000 data points from the [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution) with density\n",
    "\n",
    "$$\n",
    "f(x; \\alpha) = \\alpha \\exp(-\\alpha x)\n",
    "\\qquad\n",
    "(x > 0, \\alpha > 0)\n",
    "$$\n",
    "\n",
    "taking $\\alpha = 0.5$. Then\n",
    "\n",
    "Using the same data set, implement maximum likelihood again, but this time pretending that you don't know the analytical expression for the maximum likelihood estimator.  Instead, set up the log likelihood function and maximize it numerically using a routine from `scipy.optimize`. \n",
    "\n",
    "(Hint: Have a look at the optimization examples from the scientific Python quickstart notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Put your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a discrete Lyapunov equation is a matrix equation of the form\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    X = A X A^\\top + M\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Here all matrices are $n \\times n$ and $X$ is the unknown.  $A^\\top$ is the transpose of $A$.  The equation has a unique solution if the spectral radius of $A$ is less than 1.\n",
    "\n",
    "There is a solver for Lyapunov equations in SciPy.  Let's try it out with these matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[0, 1],[-1/2, -1]])\n",
    "M = np.array([[0, 0], [0, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  1. ],\n",
       "       [-0.5, -1. ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 9]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the solver and the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.6, -14.4],\n",
       "       [-14.4,  21.6]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import solve_discrete_lyapunov\n",
    "solve_discrete_lyapunov(A, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact it's possible to obtain this solution by iteration, starting with a guess $X_0$, such as $X_0 = M$, and then iterating on\n",
    "\n",
    "$$\n",
    "    X_{n+1} = A X_n A^\\top + M\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to obtain the same solution using an iterative scheme.  (That is, start with $X_0$, then compute $X_1$, then $X_2$, etc.  You can stop when $X_{n+1}$ and $X_n$ are close, or by using some other simpler method.  But check that you get a result close to the solution above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Put your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "The task is to compute an approximation to $\\pi$ using Monte Carlo\n",
    "\n",
    "Your hints are as follows:\n",
    "\n",
    "* If $U$ is a bivariate uniform random variable on the unit square $(0, 1)^2$, then the probability that $U$ lies in a subset $B$ of $(0,1)^2$ is equal to the area of $B$.\n",
    "* If $U_1,\\ldots,U_n$ are IID copies of $U$, then, as $n$ gets large, the fraction that falls in $B$, converges to the probability of landing in $B$.\n",
    "* For a circle, $area = \\pi * radius^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "Rewrite the Monte Carlo approximation of $\\pi$ in Exercise 8 using vectorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
