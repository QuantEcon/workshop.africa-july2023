{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Exercises"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Written for the QuantEcon Africa Workshop (July 2023)\n",
    "#### Author: [John Stachurski](http://johnstachurski.net/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you attempt these exercises, we recommend that you read\n",
    "\n",
    "1. the [lecture on NumPy](https://python-programming.quantecon.org/numpy.html),\n",
    "2. the [lecture on Matplotlib](https://python-programming.quantecon.org/matplotlib.html) and\n",
    "3. the [lecture on SciPy](https://python-programming.quantecon.org/scipy.html).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "In this exercise, \n",
    "\n",
    "1. Draw 1000 independent draws from the standard normal distribution using [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html).\n",
    "\n",
    "2. Calculate the sample mean and variance of the draws and compare them to the theoretical values.\n",
    "\n",
    "3. Visualize the empirical distribution of the draws using a histogram. Mark the sample mean and $\\pm$ one standard deviation using vertical lines.\n",
    "\n",
    "4. Calculate the probability that a draw from the distribution is less than 0 and compare it to the proportion of the sample that is less than 0.\n",
    "\n",
    "5. How do the results in 3 change with sample size? Try to draw 10, 100, 500, 1000, 10000 samples 100 times each and plot the results.\n",
    "\n",
    "Use the following imports to get started.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters of the standard normal distribution\n",
    "mu = 0\n",
    "sigma = 1\n",
    "\n",
    "# Generate a sample of 10000 draws from the normal distribution\n",
    "samples = norm.rvs(mu, sigma, size=10_000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of the sample\n",
    "mean = np.mean(samples)\n",
    "std = np.std(samples)\n",
    "\n",
    "print(\"Sample mean: {:.4f}\".format(mean))\n",
    "print(\"Theoretical mean: {:.4f}\".format(mu))\n",
    "print(\"Sample standard deviation: {:.4f}\".format(std))\n",
    "print(\"Theoretical standard deviation: {:.4f}\".format(sigma))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the sample\n",
    "plt.hist(samples, bins=100)\n",
    "plt.axvline(mean, color='red')\n",
    "plt.axvline(mean + std, color='grey')\n",
    "plt.axvline(mean - std, color='grey')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability that a draw from the distribution is less than 0\n",
    "probability = norm.cdf(0, mu, sigma)\n",
    "\n",
    "print(\"The probability that a draw from the distribution is less than 0 is:\", probability)\n",
    "\n",
    "# Calculate the proportion of samples is less than 0\n",
    "proportion = np.mean(samples < 0)\n",
    "\n",
    "print(\"The proportion of samples is less than 0 is:\", proportion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that draws n samples from \n",
    "# the standard normal distribution and returns \n",
    "# mean and starndard deviation\n",
    "def draw_samples(n):\n",
    "    samples = norm.rvs(mu, sigma, size=n)\n",
    "    mean = np.mean(samples)\n",
    "    std = np.std(samples)\n",
    "    return mean, std\n",
    "\n",
    "sample_sizes = [10, 100, 500, 1000, 10_000]\n",
    "sizes_arr = np.repeat(sample_sizes, 100)\n",
    "\n",
    "# Draw 100 samples for each sample size using vectorized numpy code\n",
    "means, stds = np.vectorize(draw_samples)(sizes_arr)\n",
    "means, stds = means.reshape(5, 100), stds.reshape(5, 100)\n",
    "\n",
    "for i in range(5):\n",
    "    # Plot scatter plot of means and standard deviations\n",
    "    plt.scatter(means[i], stds[i], alpha=0.5, \n",
    "                label=\"n = {}\".format(sample_sizes[i]))\n",
    "    plt.axhline(sigma, color='red')\n",
    "    plt.axvline(mu, color='red')\n",
    "    plt.xlabel(\"Sample mean\")\n",
    "    plt.ylabel(\"Sample standard deviation\")\n",
    "    plt.legend()\n",
    "    # Limit the axis to zoom in on the plot\n",
    "    plt.xlim(-0.5, 0.5)\n",
    "    plt.ylim(0.5, 1.5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate and plot the correlated time series\n",
    "\n",
    "$$\n",
    "    x_{t+1} = \\alpha \\, x_t + \\epsilon_{t+1}\n",
    "    \\quad \\text{where} \\quad\n",
    "    x_0 = 0 \n",
    "    \\quad \\text{and} \\quad t = 0,\\ldots,T\n",
    "$$\n",
    "\n",
    "Here $\\{\\epsilon_t\\}$ is iid and standard normal.\n",
    "\n",
    "In your solution, restrict your import statements to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import normalvariate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set $T=200$ and $\\alpha = 0.9$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Set random seed to replicate solution\n",
    "# (This is optional and used so that each time you run the cell, you get same results)\n",
    "random.seed(2023)\n",
    "\n",
    "alpha = 0.9\n",
    "ts_length = 200\n",
    "x = 0\n",
    "\n",
    "x_values = []\n",
    "for i in range(ts_length):\n",
    "    x_values.append(x)\n",
    "    x = alpha * x + normalvariate(0, 1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_values, '-')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 100000 data points from the [exponential distribution](https://en.wikipedia.org/wiki/Exponential_distribution) with density\n",
    "\n",
    "$$\n",
    "f(x; \\alpha) = \\alpha \\exp(-\\alpha x)\n",
    "\\qquad\n",
    "(x > 0, \\alpha > 0)\n",
    "$$\n",
    "\n",
    "taking $\\alpha = 0.5$. Then\n",
    "\n",
    "1. Plot a histogram of your sample and compare it to the density of the exponential distribution.\n",
    "2. After looking up the maximum likelihood estimator of $\\alpha$, compute the estimate given your data and check that it is in fact close to $\\alpha$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking [the docs for the exponential distribution](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html) we proceed as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "import numpy as np\n",
    "\n",
    "alpha = 0.5\n",
    "n = int(1e5)\n",
    "# Scale controls the exponential parameter\n",
    "ep = expon(scale=1.0/alpha)\n",
    "# Generate n randome variables\n",
    "x = ep.rvs(size=n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a histogram and density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "xmin, xmax = 0.001, 10.0\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.hist(x, density=True, bins=60, alpha=0.3)\n",
    "grid = np.linspace(xmin, xmax, 200)\n",
    "ax.plot(grid, ep.pdf(grid), 'k-', lw=2, label='true density')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's [well-known](http://en.wikipedia.org/wiki/Exponential_distribution) that the MLE of $\\alpha$ is $1/\\bar x$ where $\\bar x$ is the mean of the sample.  Let's check that it is indeed close to $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_mle = 1.0 / x.mean()\n",
    "print(f\"max likelihood estimate of alpha is {alpha_mle}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same data set, implement maximum likelihood again, but this time pretending that you don't know the analytical expression for the maximum likelihood estimator.  Instead, set up the log likelihood function and maximize it numerically using a routine from `scipy.optimize`.\n",
    "\n",
    "(Hint: Have a look at the optimization examples from the scientific Python quickstart notebook.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's set up the log likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = x.sum()\n",
    "def neg_loglike(a):\n",
    "    return - n * np.log(a) + a * s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is minus the log likelihood function for the exponential distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize over a reasonable parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "res = minimize_scalar(neg_loglike, bounds=(0.01, 10.0), method='bounded')\n",
    "res.x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is close to the analytical value of the max likelihood estimator we got in exercise 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a discrete Lyapunov equation is a matrix equation of the form\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    X = A X A' + M\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Here all matrices are $n \\times n$ and $X$ is the unknown.  $A'$ is the transpose of $A$.  The equation has a unique solution if the spectral radius of $A$ is less than 1.\n",
    "\n",
    "There is a solver for Lyapunov equations in SciPy.  Let's try it out with these matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[0, 1],[-1/2, -1]])\n",
    "M = np.array([[0, 0], [0, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the solver and the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import solve_discrete_lyapunov\n",
    "solve_discrete_lyapunov(A, M)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact it's possible to obtain this solution by iteration, starting with a guess $X_0$, such as $X_0 = M$, and then iterating on\n",
    "\n",
    "$$\n",
    "    X_{n+1} = A X_n A' + M\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to obtain the same solution using an iterative scheme.  (That is, start with $X_0$, then compute $X_1$, then $X_2$, etc.  You can stop when $X_{n+1}$ and $X_n$ are close, or by using some other simpler method.  But check that you get a result close to the solution above.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an iterative algorithm that computes the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = M\n",
    "tol = 1e-6\n",
    "max_iter = 500\n",
    "\n",
    "for i in range(max_iter):\n",
    "    P_new = A @ P @ A.T + M\n",
    "    error = np.linalg.norm(P - P_new, ord=2)\n",
    "    if error < tol:\n",
    "        break\n",
    "    P = P_new\n",
    "\n",
    "P"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is close to what we had before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_discrete_lyapunov(A, M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
